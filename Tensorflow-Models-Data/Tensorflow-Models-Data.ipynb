{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/benjaminbrown038/Machine-Learning/blob/main/Tensorflow-Models-Data/Tensorflow-Models-Data.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Using Tensorflow and NumPy to Bring in Data and Train a Computer Vision Model.\n",
        "\n",
        "1. [Imports](#imports)\n",
        "2. [Data](#data)\n",
        "3. [Training Hyperparameters](#training)\n",
        "4. [Architectures](#architectures)\n",
        "\n",
        "  A. [Model 1](#model1) \n",
        "  \n",
        "  B. [Model 2](model2)\n",
        "  \n",
        "  C. [Model 3](#model3)\n",
        "\n",
        "5. [Fitting Models](#fittingmodels)\n",
        "6. [Saving Models](#savingmodels)\n",
        "7. [Augmentating Data](#augmenting)\n"
      ],
      "metadata": {
        "id": "OO3Xv_b32rHk"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8oc_D2uigFTM"
      },
      "source": [
        "##### Imports\n",
        "<a name = 'imports'><a/>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "wM4YWqU7gFTM",
        "outputId": "8d110567-ceb1-487a-c02e-42c9e9ebed43",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting keras-tuner\n",
            "  Downloading keras_tuner-1.1.3-py3-none-any.whl (135 kB)\n",
            "\u001b[K     |████████████████████████████████| 135 kB 5.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from keras-tuner) (1.21.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from keras-tuner) (2.23.0)\n",
            "Requirement already satisfied: ipython in /usr/local/lib/python3.7/dist-packages (from keras-tuner) (7.9.0)\n",
            "Collecting kt-legacy\n",
            "  Downloading kt_legacy-1.0.4-py3-none-any.whl (9.6 kB)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from keras-tuner) (21.3)\n",
            "Requirement already satisfied: tensorboard in /usr/local/lib/python3.7/dist-packages (from keras-tuner) (2.9.1)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.7/dist-packages (from ipython->keras-tuner) (0.2.0)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.7/dist-packages (from ipython->keras-tuner) (0.7.5)\n",
            "Collecting jedi>=0.10\n",
            "  Downloading jedi-0.18.1-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.6 MB 37.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pygments in /usr/local/lib/python3.7/dist-packages (from ipython->keras-tuner) (2.6.1)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.7/dist-packages (from ipython->keras-tuner) (57.4.0)\n",
            "Requirement already satisfied: prompt-toolkit<2.1.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from ipython->keras-tuner) (2.0.10)\n",
            "Requirement already satisfied: pexpect in /usr/local/lib/python3.7/dist-packages (from ipython->keras-tuner) (4.8.0)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.7/dist-packages (from ipython->keras-tuner) (5.1.1)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from ipython->keras-tuner) (4.4.2)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.0 in /usr/local/lib/python3.7/dist-packages (from jedi>=0.10->ipython->keras-tuner) (0.8.3)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.1.0,>=2.0.0->ipython->keras-tuner) (0.2.5)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.1.0,>=2.0.0->ipython->keras-tuner) (1.15.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->keras-tuner) (3.0.9)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.7/dist-packages (from pexpect->ipython->keras-tuner) (0.7.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->keras-tuner) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->keras-tuner) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->keras-tuner) (2022.9.24)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->keras-tuner) (2.10)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras-tuner) (0.37.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras-tuner) (1.35.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras-tuner) (0.4.6)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras-tuner) (0.6.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras-tuner) (1.8.1)\n",
            "Requirement already satisfied: protobuf<3.20,>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras-tuner) (3.17.3)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras-tuner) (3.4.1)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras-tuner) (1.2.0)\n",
            "Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras-tuner) (1.49.1)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras-tuner) (1.0.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard->keras-tuner) (4.9)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard->keras-tuner) (0.2.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard->keras-tuner) (4.2.4)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard->keras-tuner) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard->keras-tuner) (5.0.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard->keras-tuner) (4.1.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard->keras-tuner) (3.9.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard->keras-tuner) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard->keras-tuner) (3.2.1)\n",
            "Installing collected packages: jedi, kt-legacy, keras-tuner\n",
            "Successfully installed jedi-0.18.1 keras-tuner-1.1.3 kt-legacy-1.0.4\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting model_profiler\n",
            "  Downloading model_profiler-1.1.8-py3-none-any.whl (6.4 kB)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.7/dist-packages (from model_profiler) (0.8.10)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from model_profiler) (1.21.6)\n",
            "Installing collected packages: model-profiler\n",
            "Successfully installed model-profiler-1.1.8\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPool2D, Flatten, Dense, Dropout\n",
        "from tensorflow.keras.losses import CategoricalCrossentropy\n",
        "from tensorflow.keras.optimizers import Adadelta, SGD, Adam\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.metrics import Accuracy\n",
        "from tensorflow.keras import backend as K\n",
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.keras.applications.vgg16 import VGG16\n",
        "from tensorflow.keras.applications.resnet50 import ResNet50\n",
        "from tensorflow.keras.applications.vgg19 import VGG19\n",
        "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
        "from tensorflow.keras.models import Model\n",
        "!pip install keras-tuner --upgrade\n",
        "import keras_tuner as kt\n",
        "!pip install model_profiler\n",
        "from model_profiler import model_profiler\n",
        "\n",
        "\n",
        "\n",
        "import numpy as np\n",
        "import datetime\n",
        "from PIL import Image\n",
        "import cv2\n",
        "import tensorflow.keras.preprocessing\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "#print(tf.__version__)\n",
        "#print(keras.__version__)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Import and Clean (Transform) Data\n",
        "<a name = 'data'><a/>"
      ],
      "metadata": {
        "id": "PGZUTZvm2AFI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Bring in Data:\", \"\\n\")\n",
        "\n",
        "(x_train,y_train),(x_test,y_test) = mnist.load_data()\n",
        "num_classes = 10\n",
        "x_train = x_train.reshape(x_train.shape[0],x_train.shape[1],x_train.shape[2],1)\n",
        "x_test = x_test.reshape(x_test.shape[0],x_test.shape[1],x_test.shape[2],1)\n",
        "x_train = x_train.astype('float32')\n",
        "x_test = x_test.astype('float32')\n",
        "\n",
        "\n",
        "print(\"\\n\",\"\\n\")\n",
        "print(\"x_train shape: \", x_train.shape)\n",
        "print(\"x_test shape: \", x_test.shape, \"\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GMGvS01N_hL4",
        "outputId": "14bcc67e-cf4d-4290-c466-a0d228d45617"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Bring in Data: \n",
            "\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n",
            "11501568/11490434 [==============================] - 0s 0us/step\n",
            "\n",
            " \n",
            "\n",
            "x_train shape:  (60000, 28, 28, 1)\n",
            "x_test shape:  (10000, 28, 28, 1) \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Targets"
      ],
      "metadata": {
        "id": "u39QUfAHJebg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Bring in Data:\", \"\\n\")\n",
        "\n",
        "\n",
        "y_train = y_train.reshape(y_train.shape[0],1)\n",
        "y_test = y_test.reshape(y_test.shape[0],1)\n",
        "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
        "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
        "\n",
        "print(\"y_train shape: \", y_train.shape)\n",
        "print(\"y_test shape: \",y_test.shape, \"\\n\")"
      ],
      "metadata": {
        "id": "mouRCG7OJelp",
        "outputId": "381c54c1-9d93-4fff-8c74-f5235b3d1feb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Bring in Data: \n",
            "\n",
            "y_train shape:  (60000, 10)\n",
            "y_test shape:  (10000, 10) \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Training Hyperparameters\n",
        "<a name = \"training\"><a/>"
      ],
      "metadata": {
        "id": "7zUCRmTy1lJE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input_shape = (28,28,1)\n",
        "img_rows = 28\n",
        "img_cols = 28\n",
        "batch_size = 128\n",
        "num_classes = 10\n",
        "epochs = 6\n",
        "\n",
        "print(\"image rows: \", img_rows)\n",
        "print(\"image columns: \", img_cols)\n",
        "print(\"batch size: \", batch_size)\n",
        "print(\"number of classes: \", num_classes)\n",
        "print(\"epochs: \", epochs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G-3FjtWa1liC",
        "outputId": "16770a07-2b46-4673-f28c-09eda55ef04f"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "image rows:  28\n",
            "image columns:  28\n",
            "batch size:  128\n",
            "number of classes:  10\n",
            "epochs:  6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### CNN Architectures\n",
        "<a name = \"architectures\"><a/>"
      ],
      "metadata": {
        "id": "rG7FjlCx2zej"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Model 1 "
      ],
      "metadata": {
        "id": "LE8QkImc3kah"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "N9aqePl1gFTQ",
        "outputId": "bac9b108-d81c-42a7-9d36-1a192f03201b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_8 (Conv2D)           (None, 26, 26, 32)        320       \n",
            "                                                                 \n",
            " conv2d_9 (Conv2D)           (None, 24, 24, 64)        18496     \n",
            "                                                                 \n",
            " max_pooling2d_8 (MaxPooling  (None, 12, 12, 64)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 12, 12, 64)        0         \n",
            "                                                                 \n",
            " flatten_2 (Flatten)         (None, 9216)              0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 128)               1179776   \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 10)                1290      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,199,882\n",
            "Trainable params: 1,199,882\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "| Model Profile                    | Value         | Unit    |\n",
            "|----------------------------------|---------------|---------|\n",
            "| Selected GPUs                    | None Detected | GPU IDs |\n",
            "| No. of FLOPs                     | 0.0002        | BFLOPs  |\n",
            "| GPU Memory Requirement           | 0.0423        | GB      |\n",
            "| Model Parameters                 | 1.1999        | Million |\n",
            "| Memory Required by Model Weights | 4.5772        | MB      |\n"
          ]
        }
      ],
      "source": [
        "model = Sequential()\n",
        "model.add(Conv2D(32,kernel_size=(3,3),activation='relu',input_shape=input_shape))\n",
        "model.add(Conv2D(64,(3,3),activation = 'relu'))\n",
        "model.add(MaxPool2D(pool_size=(2,2)))\n",
        "model.add(Dropout(.25))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(128,activation = 'relu'))\n",
        "model.add(Dense(num_classes,activation='softmax'))\n",
        "\n",
        "loss = CategoricalCrossentropy()\n",
        "sgd = SGD(learning_rate = .01)\n",
        "model.compile(loss= loss, optimizer= sgd, metrics = ['Accuracy'])\n",
        "\n",
        "model.summary()\n",
        "Batch_size = 128\n",
        "profile = model_profiler(model, Batch_size)\n",
        "\n",
        "print(profile)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Model 2 "
      ],
      "metadata": {
        "id": "mWrMt0-N3evg"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "7MNmBgMAgFTS",
        "outputId": "3dbd9c69-b3f5-4934-f0c9-5fda80b1c0f0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_4 (Conv2D)           (None, 28, 28, 8)         80        \n",
            "                                                                 \n",
            " max_pooling2d_4 (MaxPooling  (None, 14, 14, 8)        0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_5 (Conv2D)           (None, 14, 14, 64)        4672      \n",
            "                                                                 \n",
            " max_pooling2d_5 (MaxPooling  (None, 7, 7, 64)         0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_6 (Conv2D)           (None, 7, 7, 128)         73856     \n",
            "                                                                 \n",
            " max_pooling2d_6 (MaxPooling  (None, 4, 4, 128)        0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_7 (Conv2D)           (None, 4, 4, 10)          11530     \n",
            "                                                                 \n",
            " max_pooling2d_7 (MaxPooling  (None, 1, 1, 10)         0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " flatten_1 (Flatten)         (None, 10)                0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 90,138\n",
            "Trainable params: 90,138\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "| Model Profile                    | Value         | Unit    |\n",
            "|----------------------------------|---------------|---------|\n",
            "| Selected GPUs                    | None Detected | GPU IDs |\n",
            "| No. of FLOPs                     | 0.0001        | BFLOPs  |\n",
            "| GPU Memory Requirement           | 0.0154        | GB      |\n",
            "| Model Parameters                 | 0.0901        | Million |\n",
            "| Memory Required by Model Weights | 0.3438        | MB      |\n"
          ]
        }
      ],
      "source": [
        "model1 = Sequential()\n",
        "model1.add(Conv2D(8,(3,3),padding = 'same',activation = 'relu',input_shape = (28,28,1)))\n",
        "model1.add(MaxPool2D((2,2),padding = 'same'))\n",
        "model1.add(Conv2D(64,(3,3),padding='same',activation = 'relu'))\n",
        "model1.add(MaxPool2D((2,2),padding= 'same'))\n",
        "model1.add(Conv2D(128,(3,3),padding = 'same',activation = 'relu'))\n",
        "model1.add(MaxPool2D((2,2),padding = 'same'))\n",
        "model1.add(Conv2D(10,(3,3),padding = 'same',activation = 'softmax'))\n",
        "model1.add(MaxPool2D((4,4),padding = 'same'))\n",
        "model1.add(Flatten())\n",
        "\n",
        "loss = CategoricalCrossentropy()\n",
        "sgd = SGD(learning_rate = .01)\n",
        "model1.compile(loss = loss, optimizer = sgd, metrics = ['Accuracy'])\n",
        "\n",
        "model1.summary()\n",
        "Batch_size = 128\n",
        "profile = model_profiler(model1,Batch_size = Batch_size)\n",
        "\n",
        "print(profile)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Model 3 "
      ],
      "metadata": {
        "id": "v6K3vnLbvhir"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model2 = Sequential()\n",
        "model2.add(Conv2D(32,kernel_size=(3),activation='relu',input_shape=input_shape))\n",
        "model2.add(Conv2D(64,(3,3),activation = 'relu'))\n",
        "model2.add(MaxPool2D(pool_size=(2)))\n",
        "model2.add(Dropout(.25))\n",
        "model2.add(Flatten())\n",
        "model2.add(Dense(128,activation = 'relu'))\n",
        "model2.add(Dense(num_classes,activation='softmax'))\n",
        "\n",
        "loss = CategoricalCrossentropy()\n",
        "sgd = SGD(learning_rate = .01)\n",
        "model2.compile(loss = loss, optimizer = sgd, metrics = ['Accuracy'])\n",
        "\n",
        "model2.summary()\n",
        "Batch_size = 128\n",
        "profile = model_profiler(model2, Batch_size)\n",
        "\n",
        "print(profile)"
      ],
      "metadata": {
        "id": "7FCByCfupgmc",
        "outputId": "9dad5e58-6058-487f-f0f3-52560b40caec",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_10 (Conv2D)          (None, 26, 26, 32)        320       \n",
            "                                                                 \n",
            " conv2d_11 (Conv2D)          (None, 24, 24, 64)        18496     \n",
            "                                                                 \n",
            " max_pooling2d_9 (MaxPooling  (None, 12, 12, 64)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 12, 12, 64)        0         \n",
            "                                                                 \n",
            " flatten_3 (Flatten)         (None, 9216)              0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 128)               1179776   \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 10)                1290      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,199,882\n",
            "Trainable params: 1,199,882\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "| Model Profile                    | Value         | Unit    |\n",
            "|----------------------------------|---------------|---------|\n",
            "| Selected GPUs                    | None Detected | GPU IDs |\n",
            "| No. of FLOPs                     | 0.0002        | BFLOPs  |\n",
            "| GPU Memory Requirement           | 0.0423        | GB      |\n",
            "| Model Parameters                 | 1.1999        | Million |\n",
            "| Memory Required by Model Weights | 4.5772        | MB      |\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Transfer Learning"
      ],
      "metadata": {
        "id": "W9-6tVkZ_UGa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Resnet"
      ],
      "metadata": {
        "id": "YDcejvxsHarw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pretrained_model = ResNet50(weights='imagenet')\n",
        "Batch_size = 128\n",
        "profile = model_profiler(pretrained_model, Batch_size)\n",
        "\n",
        "print(profile)"
      ],
      "metadata": {
        "id": "hmNiNjNq_UNa",
        "outputId": "e701e42f-ce5f-4804-dae8-6d2186beb350",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "| Model Profile                    | Value         | Unit    |\n",
            "|----------------------------------|---------------|---------|\n",
            "| Selected GPUs                    | None Detected | GPU IDs |\n",
            "| No. of FLOPs                     | 0.0771        | BFLOPs  |\n",
            "| GPU Memory Requirement           | 17.7242       | GB      |\n",
            "| Model Parameters                 | 25.6367       | Million |\n",
            "| Memory Required by Model Weights | 97.7963       | MB      |\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### VGG16"
      ],
      "metadata": {
        "id": "jtdClIe5_UUc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pretrained_model_two = VGG16(weights='imagenet', include_top=False)\n",
        "Batch_size = 128\n",
        "profile = model_profiler(pretrained_model_two, Batch_size)\n",
        "\n",
        "print(profile)"
      ],
      "metadata": {
        "id": "LRnf5qb8_Ua-",
        "outputId": "2f672036-7e0c-45b7-fc08-edae8cce61c6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "58889256/58889256 [==============================] - 0s 0us/step\n",
            "| Model Profile                    | Value         | Unit    |\n",
            "|----------------------------------|---------------|---------|\n",
            "| Selected GPUs                    | None Detected | GPU IDs |\n",
            "| No. of FLOPs                     | 0.141         | BFLOPs  |\n",
            "| GPU Memory Requirement           | 0.0164        | GB      |\n",
            "| Model Parameters                 | 14.7147       | Million |\n",
            "| Memory Required by Model Weights | 56.1321       | MB      |\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### VGG19"
      ],
      "metadata": {
        "id": "E1LOc_Y9_Uxn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pretrained_model_three = VGG19(weights='imagenet')\n",
        "#model = Model(inputs=base_model.input, outputs=base_model.get_layer('block4_pool').output)\n",
        "Batch_size = 128\n",
        "profile = model_profiler(pretrained_model_three, Batch_size)\n",
        "\n",
        "print(profile)"
      ],
      "metadata": {
        "id": "GMu8klGY_U5L",
        "outputId": "7edfd334-0309-4622-f49b-2970c6b7efbf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "| Model Profile                    | Value         | Unit    |\n",
            "|----------------------------------|---------------|---------|\n",
            "| Selected GPUs                    | None Detected | GPU IDs |\n",
            "| No. of FLOPs                     | 0.3926        | BFLOPs  |\n",
            "| GPU Memory Requirement           | 8.0337        | GB      |\n",
            "| Model Parameters                 | 143.6672      | Million |\n",
            "| Memory Required by Model Weights | 548.047       | MB      |\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Inception V3"
      ],
      "metadata": {
        "id": "_hG6ypMeHZRb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pretrained_model_four = InceptionV3(weights='imagenet', include_top=False)\n",
        "Batch_size = 128\n",
        "profile = model_profiler(pretrained_model_four, Batch_size)\n",
        "\n",
        "print(profile)"
      ],
      "metadata": {
        "id": "bPTDA38IHZX6",
        "outputId": "7f99ec47-884d-42ae-cb30-140e1a2ec137",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "| Model Profile                    | Value         | Unit    |\n",
            "|----------------------------------|---------------|---------|\n",
            "| Selected GPUs                    | None Detected | GPU IDs |\n",
            "| No. of FLOPs                     | 0.1252        | BFLOPs  |\n",
            "| GPU Memory Requirement           | 0.0552        | GB      |\n",
            "| Model Parameters                 | 21.8028       | Million |\n",
            "| Memory Required by Model Weights | 83.171        | MB      |\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Fit Data to Models"
      ],
      "metadata": {
        "id": "BLH7A7DW3clg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Model 1 "
      ],
      "metadata": {
        "id": "OcTW7k-V3vAI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(x_train,y_train,\n",
        "         batch_size = batch_size,\n",
        "         epochs = epochs,\n",
        "         verbose = 1,\n",
        "         validation_data=(x_test,y_test))"
      ],
      "metadata": {
        "id": "roon5_2I3O8E",
        "outputId": "73c96068-4e0d-461d-89e3-cdfd2ac21d0a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/6\n",
            "469/469 [==============================] - 146s 312ms/step - loss: 0.1340 - Accuracy: 0.9580 - val_loss: 0.0933 - val_Accuracy: 0.9711\n",
            "Epoch 2/6\n",
            "469/469 [==============================] - 144s 307ms/step - loss: 0.1135 - Accuracy: 0.9648 - val_loss: 0.0817 - val_Accuracy: 0.9749\n",
            "Epoch 3/6\n",
            "469/469 [==============================] - 145s 308ms/step - loss: 0.0987 - Accuracy: 0.9685 - val_loss: 0.0771 - val_Accuracy: 0.9749\n",
            "Epoch 4/6\n",
            "469/469 [==============================] - 145s 308ms/step - loss: 0.0879 - Accuracy: 0.9720 - val_loss: 0.0779 - val_Accuracy: 0.9748\n",
            "Epoch 5/6\n",
            "469/469 [==============================] - 146s 311ms/step - loss: 0.0787 - Accuracy: 0.9752 - val_loss: 0.0683 - val_Accuracy: 0.9763\n",
            "Epoch 6/6\n",
            "469/469 [==============================] - 143s 305ms/step - loss: 0.0694 - Accuracy: 0.9778 - val_loss: 0.0630 - val_Accuracy: 0.9792\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f52ed229810>"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Model 2 "
      ],
      "metadata": {
        "id": "fjU-87Wt3wTd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model1.fit(x_train,y_train,\n",
        "            validation_data = (x_test,y_test),\n",
        "            epochs = epochs,\n",
        "            batch_size = batch_size,\n",
        "            verbose = 1)"
      ],
      "metadata": {
        "id": "XWfqfIXb3Qlx",
        "outputId": "99943af3-9640-4cd1-ebdf-261aa6140fc6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/6\n",
            "469/469 [==============================] - 71s 151ms/step - loss: 8.2157 - Accuracy: 0.0971 - val_loss: 1.6228 - val_Accuracy: 0.0982\n",
            "Epoch 2/6\n",
            "469/469 [==============================] - 70s 149ms/step - loss: 1.3033 - Accuracy: 0.1019 - val_loss: 1.1822 - val_Accuracy: 0.1015\n",
            "Epoch 3/6\n",
            "469/469 [==============================] - 68s 145ms/step - loss: 1.1534 - Accuracy: 0.1072 - val_loss: 1.1267 - val_Accuracy: 0.1168\n",
            "Epoch 4/6\n",
            "469/469 [==============================] - 68s 144ms/step - loss: 1.1172 - Accuracy: 0.1152 - val_loss: 1.1430 - val_Accuracy: 0.1495\n",
            "Epoch 5/6\n",
            "469/469 [==============================] - 68s 144ms/step - loss: 1.0972 - Accuracy: 0.1223 - val_loss: 1.1083 - val_Accuracy: 0.1323\n",
            "Epoch 6/6\n",
            "469/469 [==============================] - 67s 144ms/step - loss: 1.0850 - Accuracy: 0.1338 - val_loss: 1.0999 - val_Accuracy: 0.1539\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f52ed240210>"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Model 3 "
      ],
      "metadata": {
        "id": "_6a64UYj3yKe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model2.fit(x_train,y_train,\n",
        "            validation_data = (x_test,y_test),\n",
        "            epochs = epochs,\n",
        "            batch_size = batch_size,\n",
        "            verbose = 1)"
      ],
      "metadata": {
        "id": "h1i0muEv3Qo4",
        "outputId": "50edb9a4-2ada-4d38-adec-6bf074a3d4f0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/6\n",
            "469/469 [==============================] - 147s 312ms/step - loss: 1.6751 - Accuracy: 0.5289 - val_loss: 0.3121 - val_Accuracy: 0.9075\n",
            "Epoch 2/6\n",
            "469/469 [==============================] - 147s 312ms/step - loss: 0.2692 - Accuracy: 0.9169 - val_loss: 0.1745 - val_Accuracy: 0.9490\n",
            "Epoch 3/6\n",
            "469/469 [==============================] - 144s 306ms/step - loss: 0.1710 - Accuracy: 0.9471 - val_loss: 0.1310 - val_Accuracy: 0.9590\n",
            "Epoch 4/6\n",
            "469/469 [==============================] - 146s 311ms/step - loss: 0.1300 - Accuracy: 0.9588 - val_loss: 0.1112 - val_Accuracy: 0.9653\n",
            "Epoch 5/6\n",
            "469/469 [==============================] - 143s 305ms/step - loss: 0.1069 - Accuracy: 0.9664 - val_loss: 0.0951 - val_Accuracy: 0.9690\n",
            "Epoch 6/6\n",
            "469/469 [==============================] - 146s 312ms/step - loss: 0.0912 - Accuracy: 0.9708 - val_loss: 0.0894 - val_Accuracy: 0.9729\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f52ed0c4150>"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Directory to Save Model"
      ],
      "metadata": {
        "id": "4TAoCSHtH9NL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir -p saved_model"
      ],
      "metadata": {
        "id": "ztO5u8N7tFBq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Save Tensorflow Models"
      ],
      "metadata": {
        "id": "3BEyVFiE4FxB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Model 1 "
      ],
      "metadata": {
        "id": "AwSuXY4w47wj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.save(\"saved_model/model.h5\")\n",
        "model.load_weights(\"model.h5\")\n",
        "deploy_model = load_model(\"./model.h5\",compile = True)"
      ],
      "metadata": {
        "id": "hB7AVhyI4DQU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Model 2 "
      ],
      "metadata": {
        "id": "irC_OTY-4_py"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model1.save(\"saved_model/model1.h5\")\n",
        "model1.load_weights(\"model1.h5\")\n",
        "deploy_model1 = load_model(\"./model1.h5\",compile = True)"
      ],
      "metadata": {
        "id": "XrpK-stC4DTb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Model 3 "
      ],
      "metadata": {
        "id": "lrlRJnMM5X_H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model2.save(\"saved_model/model2.h5\")\n",
        "model2.load_weights(\"model2.h5\")\n",
        "deploy_model2 = load_model(\"./model2.h5\",compile = True)"
      ],
      "metadata": {
        "id": "mnulwajN4DWD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Checking Model Accuracy"
      ],
      "metadata": {
        "id": "SGmkJbzWs5r2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Model 1"
      ],
      "metadata": {
        "id": "scIXKcups5z5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = tf.keras.models.load_model('saved_model/model')\n",
        "loss, acc = model.evaluate(test_images, test_labels, verbose=2)\n",
        "print('Restored model, accuracy: {:5.2f}%'.format(100 * acc))\n",
        "print(model.predict(test_images).shape)"
      ],
      "metadata": {
        "id": "1e6_d01fs6IP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Model 2"
      ],
      "metadata": {
        "id": "CCLMg5gcs61A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model1 = tf.keras.models.load_model('saved_model/model')\n",
        "loss, acc = model1.evaluate(test_images, test_labels, verbose=2)\n",
        "print('Restored model, accuracy: {:5.2f}%'.format(100 * acc))\n",
        "print(model1.predict(test_images).shape)"
      ],
      "metadata": {
        "id": "pv4SXwvqs69n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Model 3"
      ],
      "metadata": {
        "id": "d8DjSPexs7GO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model2 = tf.keras.models.load_model('saved_model/model')\n",
        "loss, acc = model2.evaluate(test_images, test_labels, verbose=2)\n",
        "print('Restored model, accuracy: {:5.2f}%'.format(100 * acc))\n",
        "print(model2.predict(test_images).shape)"
      ],
      "metadata": {
        "id": "2gRwE58As7PT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Tuning Models"
      ],
      "metadata": {
        "id": "uxFG1E6Sv89x"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Model 1 "
      ],
      "metadata": {
        "id": "Jj6lqO5_v9JN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input_shape = (1,28,28)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "hp_units = hp.Int('units',min_value = 32, max_value = 512, step 32)\n",
        "model.add(keras.layers.Denser(units = hp_units,activation='relu'))\n",
        "model.add(keras.layers.Dense(10))\n",
        "\n",
        "\n",
        "\n",
        "def model_builder(hp):\n",
        "    model = Sequential()\n",
        "    model.add(Conv2D(32,kernel_size=(3,3),activation='relu',input_shape=input_shape))\n",
        "    model.add(Conv2D(64,(3,3),activation = 'relu'))\n",
        "    model.add(MaxPool2D(pool_size=(2,2)))\n",
        "    model.add(Dropout(.25))\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(128,activation = 'relu'))\n",
        "    model.add(Dense(num_classes,activation='softmax'))\n",
        "\n",
        "    # Tune the number of units in the first Dense layer\n",
        "    # Choose an optimal value between 32-512\n",
        "    hp_units = hp.Int('units', min_value=32, max_value=512, step=32)\n",
        "    model.add(keras.layers.Dense(units=hp_units, activation='relu'))\n",
        "    model.add(keras.layers.Dense(10))\n",
        "\n",
        "    # Tune the learning rate for the optimizer\n",
        "    # Choose an optimal value from 0.01, 0.001, or 0.0001\n",
        "    hp_learning_rate = hp.Choice('learning_rate', values=[1e-2, 1e-3, 1e-4])\n",
        "\n",
        "    model.compile(optimizer=keras.optimizers.Adam(learning_rate=hp_learning_rate),\n",
        "                loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "                metrics=['accuracy'])\n",
        "\n",
        "    return model\n",
        "\n",
        "tuner = kt.Hyperband(model_builder,\n",
        "                     objective='val_accuracy',\n",
        "                     max_epochs=10,\n",
        "                     factor=3,\n",
        "                     directory='my_dir',\n",
        "                     project_name='intro_to_kt')\n",
        "\n",
        "# keras tuner for models\n"
      ],
      "metadata": {
        "id": "K85aTabWI8iG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def model_builder(hp):\n",
        "    model = keras.Sequential()\n",
        "    model.add(keras.layers.Flatten(input_shape=(28, 28)))\n",
        "\n",
        "  # Tune the number of units in the first Dense layer\n",
        "  # Choose an optimal value between 32-512\n",
        "    hp_units = hp.Int('units', min_value=32, max_value=512, step=32)\n",
        "    model.add(keras.layers.Dense(units=hp_units, activation='relu'))\n",
        "    model.add(keras.layers.Dense(10))\n",
        "\n",
        "  # Tune the learning rate for the optimizer\n",
        "  # Choose an optimal value from 0.01, 0.001, or 0.0001\n",
        "    hp_learning_rate = hp.Choice('learning_rate', values=[1e-2, 1e-3, 1e-4])\n",
        "\n",
        "    model.compile(optimizer=keras.optimizers.Adam(learning_rate=hp_learning_rate),\n",
        "                loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "                metrics=['accuracy'])\n",
        "    \n",
        "    return model\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "tuner = kt.Hyperband(model_builder,\n",
        "                     objective='val_accuracy',\n",
        "                     max_epochs=10,\n",
        "                     factor=3,\n",
        "                     directory='my_dir',\n",
        "                     project_name='intro_to_kt')\n",
        "\n",
        "stop_early = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5)\n",
        "tuner.search(img_train, label_train, epochs=50, validation_split=0.2, callbacks=[stop_early])\n",
        "best_hps=tuner.get_best_hyperparameters(num_trials=1)[0]\n",
        "\n",
        "print(f\"\"\"\n",
        "The hyperparameter search is complete. The optimal number of units in the first densely-connected\n",
        "layer is {best_hps.get('units')} and the optimal learning rate for the optimizer\n",
        "is {best_hps.get('learning_rate')}.\n",
        "\"\"\")\n",
        "\n",
        "# Build the model with the optimal hyperparameters and train it on the data for 50 epochs\n",
        "model = tuner.hypermodel.build(best_hps)\n",
        "history = model.fit(img_train, label_train, epochs=50, validation_split=0.2)\n",
        "\n",
        "val_acc_per_epoch = history.history['val_accuracy']\n",
        "best_epoch = val_acc_per_epoch.index(max(val_acc_per_epoch)) + 1\n",
        "print('Best epoch: %d' % (best_epoch,))\n",
        "\n",
        "hypermodel = tuner.hypermodel.build(best_hps)\n",
        "\n",
        "# Retrain the model\n",
        "hypermodel.fit(img_train, label_train, epochs=best_epoch, validation_split=0.2)\n",
        "\n",
        "eval_result = hypermodel.evaluate(img_test, label_test)\n",
        "print(\"[test loss, test accuracy]:\", eval_result)"
      ],
      "metadata": {
        "id": "iGnbAL1Kv9Xy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Model 2"
      ],
      "metadata": {
        "id": "-K1qe6wtv9fG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def model_builder(hp):\n",
        "    model = keras.Sequential()\n",
        "    model.add(keras.layers.Flatten(input_shape=(28, 28)))\n",
        "\n",
        "  # Tune the number of units in the first Dense layer\n",
        "  # Choose an optimal value between 32-512\n",
        "    hp_units = hp.Int('units', min_value=32, max_value=512, step=32)\n",
        "    model.add(keras.layers.Dense(units=hp_units, activation='relu'))\n",
        "    model.add(keras.layers.Dense(10))\n",
        "\n",
        "  # Tune the learning rate for the optimizer\n",
        "  # Choose an optimal value from 0.01, 0.001, or 0.0001\n",
        "    hp_learning_rate = hp.Choice('learning_rate', values=[1e-2, 1e-3, 1e-4])\n",
        "\n",
        "    model.compile(optimizer=keras.optimizers.Adam(learning_rate=hp_learning_rate),\n",
        "                loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "                metrics=['accuracy'])\n",
        "\n",
        "    return model\n",
        "\n",
        "\n",
        "tuner = kt.Hyperband(model_builder,\n",
        "                     objective='val_accuracy',\n",
        "                     max_epochs=10,\n",
        "                     factor=3,\n",
        "                     directory='my_dir',\n",
        "                     project_name='intro_to_kt')\n",
        "\n",
        "stop_early = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5)\n",
        "\n",
        "tuner.search(img_train, label_train, epochs=50, validation_split=0.2, callbacks=[stop_early])\n",
        "\n",
        "# Get the optimal hyperparameters\n",
        "best_hps=tuner.get_best_hyperparameters(num_trials=1)[0]\n",
        "\n",
        "print(f\"\"\"\n",
        "The hyperparameter search is complete. The optimal number of units in the first densely-connected\n",
        "layer is {best_hps.get('units')} and the optimal learning rate for the optimizer\n",
        "is {best_hps.get('learning_rate')}.\n",
        "\"\"\")\n",
        "\n",
        "\n",
        "# Build the model with the optimal hyperparameters and train it on the data for 50 epochs\n",
        "model = tuner.hypermodel.build(best_hps)\n",
        "history = model.fit(img_train, label_train, epochs=50, validation_split=0.2)\n",
        "\n",
        "val_acc_per_epoch = history.history['val_accuracy']\n",
        "best_epoch = val_acc_per_epoch.index(max(val_acc_per_epoch)) + 1\n",
        "print('Best epoch: %d' % (best_epoch,))\n",
        "\n",
        "hypermodel = tuner.hypermodel.build(best_hps)\n",
        "\n",
        "# Retrain the model\n",
        "hypermodel.fit(img_train, label_train, epochs=best_epoch, validation_split=0.2)\n",
        "\n",
        "eval_result = hypermodel.evaluate(img_test, label_test)\n",
        "print(\"[test loss, test accuracy]:\", eval_result)"
      ],
      "metadata": {
        "id": "AzP7Xhsnv9mJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Model 3 "
      ],
      "metadata": {
        "id": "FeNtvadpv9sn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def model_builder(hp):\n",
        "    model = keras.Sequential()\n",
        "    model.add(keras.layers.Flatten(input_shape=(28, 28)))\n",
        "\n",
        "  # Tune the number of units in the first Dense layer\n",
        "  # Choose an optimal value between 32-512\n",
        "    hp_units = hp.Int('units', min_value=32, max_value=512, step=32)\n",
        "    model.add(keras.layers.Dense(units=hp_units, activation='relu'))\n",
        "    model.add(keras.layers.Dense(10))\n",
        "\n",
        "  # Tune the learning rate for the optimizer\n",
        "  # Choose an optimal value from 0.01, 0.001, or 0.0001\n",
        "    hp_learning_rate = hp.Choice('learning_rate', values=[1e-2, 1e-3, 1e-4])\n",
        "\n",
        "    model.compile(optimizer=keras.optimizers.Adam(learning_rate=hp_learning_rate),\n",
        "                loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "                metrics=['accuracy'])\n",
        "\n",
        "    return model\n",
        "\n",
        "\n",
        "tuner = kt.Hyperband(model_builder,\n",
        "                     objective='val_accuracy',\n",
        "                     max_epochs=10,\n",
        "                     factor=3,\n",
        "                     directory='my_dir',\n",
        "                     project_name='intro_to_kt')\n",
        "\n",
        "stop_early = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5)\n",
        "\n",
        "\n",
        "tuner.search(img_train, label_train, epochs=50, validation_split=0.2, callbacks=[stop_early])\n",
        "\n",
        "# Get the optimal hyperparameters\n",
        "best_hps=tuner.get_best_hyperparameters(num_trials=1)[0]\n",
        "\n",
        "print(f\"\"\"\n",
        "The hyperparameter search is complete. The optimal number of units in the first densely-connected\n",
        "layer is {best_hps.get('units')} and the optimal learning rate for the optimizer\n",
        "is {best_hps.get('learning_rate')}.\n",
        "\"\"\")\n",
        "\n",
        "# Build the model with the optimal hyperparameters and train it on the data for 50 epochs\n",
        "model = tuner.hypermodel.build(best_hps)\n",
        "history = model.fit(img_train, label_train, epochs=50, validation_split=0.2)\n",
        "\n",
        "val_acc_per_epoch = history.history['val_accuracy']\n",
        "best_epoch = val_acc_per_epoch.index(max(val_acc_per_epoch)) + 1\n",
        "print('Best epoch: %d' % (best_epoch,))\n",
        "\n",
        "hypermodel = tuner.hypermodel.build(best_hps)\n",
        "\n",
        "# Retrain the model\n",
        "hypermodel.fit(img_train, label_train, epochs=best_epoch, validation_split=0.2)\n",
        "\n",
        "eval_result = hypermodel.evaluate(img_test, label_test)\n",
        "print(\"[test loss, test accuracy]:\", eval_result)"
      ],
      "metadata": {
        "id": "0LjDECc_v-Nd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Augmenting Image Data in Keras and Converting to Examples and Targets for Model"
      ],
      "metadata": {
        "id": "KPq2hu5gPspY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Accessing data in file path, open image with PIL as image object, convert to numpy array, stack using concatenate function in numpy. User inputs file path, function does the rest. "
      ],
      "metadata": {
        "id": "DbVs7Y5HQBHg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def load_data(file_path):\n",
        "    file_path = Path(file_path)\n",
        "    stacked_data = np.concatenate((np.array([(Image.open(i)) for i in file_path])))\n",
        "    return stacked_data"
      ],
      "metadata": {
        "id": "dy7dvfMyQBP3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### User inputs file path and augmentation techniques. Returns a keras object that converts images in file path to each applied augmentation strategy and saves as keras object. "
      ],
      "metadata": {
        "id": "EFWu7LJ2QBVB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def DataFromFile(file_path,**kwargs):\n",
        "    img = tensorflow.keras.preprocessing.image.ImageDataGenerator()\n",
        "    data = img.flow_from_directory(file_path,**kwargs)\n",
        "    return data"
      ],
      "metadata": {
        "id": "JyZL6pVAQBaw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### User inputs keras object containing data from augmented data in folder. Returns numpy arrays as training examples and target examples as two seperate variables. "
      ],
      "metadata": {
        "id": "MXPRLkxsQBf-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def Image_Data_Generator2(data):\n",
        "    x_train = (np.array([data[0][0]]))\n",
        "    return x_train\n",
        "    y_train = (np.array(data[0][1]))\n",
        "    return y_train"
      ],
      "metadata": {
        "id": "A0YJLtkXQBlb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Transforms images to arrays."
      ],
      "metadata": {
        "id": "PMToK16iQBq6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def image_to_array(image):\n",
        "    array = tensorflow.keras.preprocessing.image.img_to_array(image_to_array)\n",
        "    return array"
      ],
      "metadata": {
        "id": "-Ga13dKuQBwo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Converts a numpy array that represents an image into a tensorflow image. "
      ],
      "metadata": {
        "id": "yo0wYElYQB2I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def array_to_image(array):\n",
        "    image = tensorflow.keras.preprocessing.image.array_to_img(image)\n",
        "    return image"
      ],
      "metadata": {
        "id": "MVlnz9VIQB7k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Splits augmented data object into training examples. "
      ],
      "metadata": {
        "id": "Tghz8r7sGKPf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def x_train_augment(image_generator_object):\n",
        "    length = len(image_generator_object)\n",
        "    mini_batch = (image_generator_object[0][0].shape)[0]\n",
        "    list1 = []\n",
        "    for i in range(length):\n",
        "        for j in range(mini_batch):\n",
        "            new_array = image_generator_object[i][0][j]\n",
        "            array = np.expand_dims(new_array,axis=0)\n",
        "            list1.append(array)\n",
        "    data = np.concatenate(list1)\n",
        "    return data"
      ],
      "metadata": {
        "id": "0R1L9N2aGKXk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Splits augmented data object into training targets. "
      ],
      "metadata": {
        "id": "hPjD3P-5GKe3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def y_train_augment(image_generator_object):\n",
        "    length = len(image_generator_object)\n",
        "    mini_batch = (image_generator_object[0][0].shape)[0]\n",
        "    list1 = []\n",
        "    for i in range(length):\n",
        "        for j in range(mini_batch):\n",
        "            new_array = image_generator_object[i][0][j]\n",
        "            array = np.expand_dims(new_array,axis=0)\n",
        "            list1.append(array)\n",
        "    data = np.concatenate(list1)\n",
        "    return data"
      ],
      "metadata": {
        "id": "MSPXL8sxGKl4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### References\n",
        "\n",
        "- https://www.tensorflow.org/tutorials/keras/keras_tuner\n",
        "- https://keras.io/api/applications/\n",
        "- https://pypi.org/project/model-profiler/"
      ],
      "metadata": {
        "id": "FNgxP4Ir4Vax"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install -q -U keras-tuner"
      ],
      "metadata": {
        "id": "IiDG9eUO4fUY"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.9"
    },
    "colab": {
      "name": "Tensorflow-CNN-Models.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}